{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expand Dataframes Based on Family Types and Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from config import COUNTRY_CODE, COUNTRY_CODE_TO_NAME, COUNTRIES, \\\n",
    "    JSON_MASTER_FILE_PATH, YEARLY_FILE_TEMPLATE, \\\n",
    "    FAMILY_NOISE_FACTOR, WEATHER_NOISE_FACTOR, \\\n",
    "    EXP_PROFILES_EXPAND_PATH, EXP_WEATHER_EXPAND_PATH, \\\n",
    "    WEATHER_COMBINED_PATH, FAMILY_COMBINED_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_file(country_code, output_file):\n",
    "    \"\"\"\n",
    "    Loads the master file for a specific country.\n",
    "\n",
    "    Parameters:\n",
    "    - country_code (str): ISO country code to identify the file.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The master dataframe for the specified country.\n",
    "    \"\"\"\n",
    "    file_path = f\"{output_file}_{country_code}.csv\"\n",
    "    master_df = pd.read_csv(file_path, parse_dates=['datetime'])\n",
    "\n",
    "    # Create the 'pattern' column in master_df\n",
    "    if 'pattern' not in master_df.columns:\n",
    "        master_df['pattern'] = master_df.apply(\n",
    "            lambda row: 'Weekend' if row['is_weekend'] == 1 or row['is_holiday'] == 1 else 'Weekday', axis=1\n",
    "        )\n",
    "        print(\"\\tCreated 'pattern' column in master_df.\")\n",
    "\n",
    "    return master_df\n",
    "\n",
    "def get_family_types_for_country(country_name, family_types_json):\n",
    "    \"\"\"\n",
    "    Extract family types for a specific country from the loaded JSON.\n",
    "\n",
    "    Parameters:\n",
    "    - country_name (str): Name of the country.\n",
    "    - family_types_json (list): The loaded JSON as a list of dictionaries.\n",
    "\n",
    "    Returns:\n",
    "    - list: List of family types for the specified country, or an empty list if not found.\n",
    "    \"\"\"\n",
    "    for entry in family_types_json:\n",
    "        if entry.get('Country') == country_name:\n",
    "            return [family['Family Type'] for family in entry.get('Families', [])]\n",
    "    return []\n",
    "\n",
    "def load_family_csv(directory, country_name, family_type):\n",
    "    \"\"\"\n",
    "    Load a family CSV file based on the country name and family type.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory containing the CSV files.\n",
    "    - country_name (str): Name of the country.\n",
    "    - family_type (str): Family type for the country.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame or None: DataFrame if the file exists, otherwise None.\n",
    "    \"\"\"\n",
    "    # Prepare the country name and family type for file searching\n",
    "    formatted_country = country_name.replace(\" \", \"-\")\n",
    "    formatted_family_type = family_type.replace(\" \", \"-\").replace(\"'\", \"-\")\n",
    "    \n",
    "    # Construct the file name\n",
    "    file_name = f\"{formatted_country}_{formatted_family_type}_combined.csv\"\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        # Load the CSV into a DataFrame\n",
    "        print(f\"  Loaded: {file_name}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"\\tFile not found: {file_name}\")\n",
    "        return None\n",
    "\n",
    "def load_weather_csv(directory, country_name):\n",
    "    \"\"\"\n",
    "    Load a weather CSV file based on the country name.\n",
    "\n",
    "    Parameters:\n",
    "    - directory (str): Path to the directory containing the CSV files.\n",
    "    - country_name (str): Name of the country.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame or None: DataFrame if the file exists, otherwise None.\n",
    "    \"\"\"\n",
    "    # Prepare the country name and family type for file searching\n",
    "    formatted_country = country_name.replace(\" \", \"-\")\n",
    "    \n",
    "    # Construct the file name\n",
    "    file_name = f\"{formatted_country}_weather_combined.csv\"\n",
    "    file_path = os.path.join(directory, file_name)\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.isfile(file_path):\n",
    "        # Load the CSV into a DataFrame\n",
    "        print(f\"  Loaded: {file_name}\")\n",
    "        return pd.read_csv(file_path)\n",
    "    else:\n",
    "        print(f\"\\tFile not found: {file_name}\")\n",
    "        return None\n",
    "\n",
    "def apply_dynamic_noise(expanded_df, col, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Apply dynamic noise to a column in a DataFrame based on its statistical properties.\n",
    "\n",
    "    Parameters:\n",
    "    - expanded_df (pd.DataFrame): The DataFrame containing the column.\n",
    "    - col (str): The column to which noise is applied.\n",
    "    - noise_factor (float): A scaling factor for the noise (default=0.1).\n",
    "\n",
    "    Returns:\n",
    "    - pd.Series: The column with dynamic noise applied.\n",
    "    \"\"\"\n",
    "    # Calculate mean and standard deviation of the column\n",
    "    col_mean = expanded_df[col].mean()\n",
    "    col_std = expanded_df[col].std()\n",
    "    # display(f\"Mean: {col_mean}, Std: {col_std}\")\n",
    "\n",
    "    # Dynamically scale the noise based on column properties\n",
    "    # Option 1: Noise proportional to standard deviation\n",
    "    # scaled_noise = np.random.normal(0, noise_factor * col_std, size=len(expanded_df))\n",
    "    \n",
    "    # Option 2: Noise proportional to mean\n",
    "    scaled_noise = np.random.normal(0, noise_factor * col_mean, size=len(expanded_df))\n",
    "    \n",
    "    return np.round(expanded_df[col] + scaled_noise, 3)\n",
    "\n",
    "def expand_family_data(master_df, family_df, main_dir, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Expand family data for the full year using the master data.\n",
    "\n",
    "    Parameters:\n",
    "    - master_df (pd.DataFrame): The full-year master data (hourly steps).\n",
    "    - family_df (pd.DataFrame): The family consumption data (template for expansion).\n",
    "    - noise_factor (float): The factor to apply random noise to consumption values.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Expanded DataFrame with family data for the full year.\n",
    "    \"\"\"\n",
    "    # Normalize column names (convert to lowercase and strip whitespace)\n",
    "    master_df.columns = master_df.columns.str.lower().str.strip()\n",
    "    family_df.columns = family_df.columns.str.lower().str.strip()\n",
    "\n",
    "    # Debug: Print columns to verify alignment\n",
    "    # print(\"\\tUnified Master DataFrame Columns:\", master_df.columns.tolist())\n",
    "    # print(\"\\tUnified Family DataFrame Columns:\", family_df.columns.tolist())\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_columns = [\"season\", \"pattern\", \"hour\"]\n",
    "    for col in required_columns:\n",
    "        if col not in master_df.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing in master_df.\")\n",
    "        if col not in family_df.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing in family_df.\")\n",
    "\n",
    "    # Merge master with family template based on Season, Pattern, and Hour\n",
    "    expanded_df = pd.merge(\n",
    "        master_df,\n",
    "        family_df,\n",
    "        on=[\"season\", \"pattern\", \"hour\"],\n",
    "        how=\"left\",\n",
    "        suffixes=('', '_template')\n",
    "    )\n",
    "    \n",
    "    # Apply noise to consumption columns\n",
    "    consumption_columns = [col for col in expanded_df.columns if \"consumption\" in col]\n",
    "    for col in consumption_columns:\n",
    "        if col.endswith('_template'):  # Skip template columns\n",
    "            continue\n",
    "        # expanded_df[col] = np.round(expanded_df[col] * (1 + np.random.uniform(-noise_factor, noise_factor, len(expanded_df))),3)\n",
    "        expanded_df[col] = apply_dynamic_noise(expanded_df, col, noise_factor).clip(lower=0)\n",
    "\n",
    "    # Recalculate Total_Electricity_Usage as the sum of all individual consumption columns\n",
    "    expanded_df['total_electricity_usage'] = np.round(expanded_df[consumption_columns].sum(axis=1), 3)\n",
    "\n",
    "    # Drop the template columns (if any)\n",
    "    expanded_df = expanded_df[[col for col in expanded_df.columns if not col.endswith('_template')]]\n",
    "    expanded_df = expanded_df[[col for col in expanded_df.columns if not col.endswith('_action')]]\n",
    "    expanded_df.drop(columns=['country', 'family_type', 'holiday_desc', 'year', 'month', 'day', 'hour'], inplace=True)\n",
    "\n",
    "    # Prepare the country name and family type for safe file saving\n",
    "    formatted_country = family_df['country'][0].replace(\" \", \"-\")\n",
    "    formatted_family_type = family_df['family_type'][0].replace(\" \", \"-\").replace(\"'\", \"-\")\n",
    "    \n",
    "    # save the expanded data to a csv file\n",
    "    expanded_df.to_csv(f'{main_dir}/{formatted_country}_{formatted_family_type}_expanded.csv', index=False)\n",
    "\n",
    "    return expanded_df\n",
    "\n",
    "def expand_weather_data(master_df, weather_df, main_dir, noise_factor=0.1):\n",
    "    \"\"\"\n",
    "    Expand weather data for the full year using the master data.\n",
    "\n",
    "    Parameters:\n",
    "    - master_df (pd.DataFrame): The full-year master data (hourly steps).\n",
    "    - weather_df (pd.DataFrame): The weather consumption data (template for expansion).\n",
    "    - noise_factor (float): The factor to apply random noise to consumption values.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: Expanded DataFrame with weatehr data for the full year.\n",
    "    \"\"\"\n",
    "    # Normalize column names (convert to lowercase and strip whitespace)\n",
    "    master_df.columns = master_df.columns.str.lower().str.strip()\n",
    "    weather_df.columns = weather_df.columns.str.lower().str.strip()\n",
    "\n",
    "    # Debug: Print columns to verify alignment\n",
    "    # print(\"\\tUnified Master DataFrame Columns:\", master_df.columns.tolist())\n",
    "    # print(\"\\tUnified Weather DataFrame Columns:\", weather_df.columns.tolist())\n",
    "\n",
    "    # Ensure required columns are present\n",
    "    required_columns = [\"season\", \"hour\"]\n",
    "    for col in required_columns:\n",
    "        if col not in master_df.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing in master_df.\")\n",
    "        if col not in weather_df.columns:\n",
    "            raise KeyError(f\"Column '{col}' is missing in weather_df.\")\n",
    "\n",
    "    # Merge master with family template based on Season, Pattern, and Hour\n",
    "    expanded_df = pd.merge(\n",
    "        master_df,\n",
    "        weather_df,\n",
    "        on=[\"season\", \"hour\"],\n",
    "        how=\"left\",\n",
    "        suffixes=('', '_template')\n",
    "    )\n",
    "    \n",
    "    # Apply noise to consumption columns\n",
    "    consumption_columns = [col for col in expanded_df.columns if \"value\" in col]\n",
    "    for col in consumption_columns:\n",
    "        if col.endswith('_template'):  # Skip template columns\n",
    "            continue\n",
    "        expanded_df[col] = np.round(expanded_df[col] * (1 + np.random.uniform(-noise_factor, noise_factor, len(expanded_df))),3)\n",
    "\n",
    "    # Drop the template columns (if any)\n",
    "    expanded_df = expanded_df[[col for col in expanded_df.columns if not col.endswith('_template')]]\n",
    "    expanded_df = expanded_df[[col for col in expanded_df.columns if not col.endswith('_description')]]\n",
    "    expanded_df.drop(columns=['country', 'holiday_desc', 'year', 'month', 'day', 'hour'], inplace=True)\n",
    "\n",
    "    # Prepare the country name and family type for safe file saving\n",
    "    formatted_country = weather_df['country'][0].replace(\" \", \"-\")\n",
    "    \n",
    "    # save the expanded data to a csv file\n",
    "    expanded_df.to_csv(f'{main_dir}/{formatted_country}_weather_expanded.csv', index=False)\n",
    "\n",
    "    return expanded_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Family Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json file\n",
    "with open(JSON_MASTER_FILE_PATH, \"r\") as f:\n",
    "    family_types_json = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Family Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(EXP_PROFILES_EXPAND_PATH):\n",
    "    os.makedirs(EXP_PROFILES_EXPAND_PATH)\n",
    "\n",
    "for country_code in COUNTRY_CODE:\n",
    "    if COUNTRY_CODE_TO_NAME.get(country_code) in COUNTRIES:\n",
    "        country_processed = COUNTRY_CODE_TO_NAME[country_code]\n",
    "        print(f\"\\nProcessing data for {country_processed} ({country_code})\")\n",
    "        \n",
    "        try:\n",
    "            master_df = load_master_file(country_code, YEARLY_FILE_TEMPLATE)\n",
    "            print(f\"\\nMaster File for {country_code}:\")\n",
    "            # display(master_df.head(2))\n",
    "\n",
    "            family_types_per_country = get_family_types_for_country(country_processed, family_types_json)\n",
    "            # display(family_types_per_country)\n",
    "\n",
    "            try:\n",
    "                for family_type in family_types_per_country:\n",
    "                    print(f\"  Family Type: {family_type}\")\n",
    "                    family_df = load_family_csv(FAMILY_COMBINED_PATH, country_processed, family_type)\n",
    "                    # display(family_df.head(2))\n",
    "\n",
    "                    # Apply the function\n",
    "                    full_year_family_data = expand_family_data(master_df, family_df, EXP_PROFILES_EXPAND_PATH, noise_factor=FAMILY_NOISE_FACTOR)\n",
    "\n",
    "                    # Display the first few rows\n",
    "                    # display(full_year_family_data.head(2))\n",
    "                    # break\n",
    "                # break\n",
    "            except Exception as e:\n",
    "                print(f\"\\t2.Error: {e}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"\\t1.Error: {e}\")\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expand Weather Profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(EXP_WEATHER_EXPAND_PATH):\n",
    "    os.makedirs(EXP_WEATHER_EXPAND_PATH)\n",
    "\n",
    "\n",
    "for country_code in COUNTRY_CODE:\n",
    "    if COUNTRY_CODE_TO_NAME.get(country_code) in COUNTRIES:\n",
    "        country_processed = COUNTRY_CODE_TO_NAME[country_code]\n",
    "        print(f\"\\nProcessing data for {country_processed} ({country_code})\")\n",
    "    \n",
    "        try:\n",
    "            master_df = load_master_file(country_code, YEARLY_FILE_TEMPLATE)\n",
    "            print(f\"\\nMaster File for {country_code}:\")\n",
    "            # display(master_df.head(2))\n",
    "\n",
    "            weather_df = load_weather_csv(WEATHER_COMBINED_PATH, country_processed)\n",
    "            # display(weather_df.head(2))\n",
    "\n",
    "            # Apply the function\n",
    "            full_year_weather_data = expand_weather_data(master_df, weather_df, EXP_WEATHER_EXPAND_PATH, noise_factor=WEATHER_NOISE_FACTOR)\n",
    "\n",
    "            # Display the first few rows\n",
    "            # display(full_year_weather_data.head(2))\n",
    "            # break\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
