{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from config import SEASON_COLORS, AGGREGATE_BY, NUMBER_FAMILIES_PER_COUNTRY, JSON_MASTER_FILE_PATH, SAVE_PLOTS, \\\n",
    "    EXP_PROFILES_EXPAND_PATH, EXP_WEATHER_EXPAND_PATH, CSV_FINAL_PROFILES_WEATHER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Family Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the json file\n",
    "with open(JSON_MASTER_FILE_PATH, \"r\") as f:\n",
    "    family_types_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_family_json(json_data):\n",
    "    \"\"\"\n",
    "    Processes the JSON data to create a mapping of family types and member counts per country.\n",
    "\n",
    "    Parameters:\n",
    "    - json_data (list): JSON data loaded as a Python list.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary with country-specific family types and their member counts.\n",
    "    \"\"\"\n",
    "    family_member_counts = {}\n",
    "    for entry in json_data:\n",
    "        country = entry['Country']\n",
    "        families = entry['Families']\n",
    "        family_member_counts[country] = {\n",
    "            family['Family Type']: len(family['Members']) for family in families\n",
    "        }\n",
    "    \n",
    "    return family_member_counts\n",
    "\n",
    "family_member_counts = process_family_json(family_types_json)\n",
    "# display(family_member_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_csv_mapping(PROJ_PATH, family_types_json, process_type):    \n",
    "    if process_type == \"family\":\n",
    "        family_types = {entry[\"Country\"]: [family[\"Family Type\"] for family in entry[\"Families\"]] for entry in family_types_json}\n",
    "        \n",
    "        # Extract countries and families\n",
    "        countries = [entry[\"Country\"] for entry in family_types_json]\n",
    "        # print(\"Available Countries:\", countries)\n",
    "        # print(\"Family Types by Country:\", family_types)\n",
    "\n",
    "        # Get all CSV file paths in the folder\n",
    "        csv_files = glob.glob(f\"{PROJ_PATH}/*.csv\")\n",
    "\n",
    "        # Create a dictionary to map parsed JSON to CSV files\n",
    "        csv_mapping = {}\n",
    "        for country, families in family_types.items():\n",
    "            csv_mapping[country] = {}\n",
    "            for family_type in families:\n",
    "                # Find matching CSV files for this country and family type\n",
    "                family_type_clean = family_type.replace(' ', '-').replace(\"'\", '-')\n",
    "                matching_files = [\n",
    "                    # file for file in csv_files if f\"{country}_{family_type.replace(' ', '_')}\" in file\n",
    "                    file for file in csv_files if f\"{country.replace(' ', '-')}_{family_type_clean}\" in file\n",
    "                ]\n",
    "                csv_mapping[country][family_type] = matching_files\n",
    "\n",
    "        # # Check the mapping\n",
    "        # for country, families in csv_mapping.items():\n",
    "        #     print(f\"Country: {country}\")\n",
    "        #     for family, files in families.items():\n",
    "        #         file_names = [os.path.basename(file) for file in files]\n",
    "        #         print(f\"  Family Type: {family} -> Files: {file_names}\")\n",
    "                \n",
    "    elif process_type == \"weather\":        \n",
    "        # Extract countries\n",
    "        countries = [entry[\"Country\"] for entry in family_types_json]\n",
    "        # print(\"Available Countries:\", countries)\n",
    "        # print(\"Weather by Country\")\n",
    "\n",
    "        # Get all CSV file paths in the folder\n",
    "        csv_files = glob.glob(f\"{PROJ_PATH}/*.csv\")\n",
    "\n",
    "        # Create a dictionary to map parsed JSON to CSV files\n",
    "        csv_mapping = {}\n",
    "        for country in countries:\n",
    "            # Find matching CSV files for this country\n",
    "            matching_files = [\n",
    "                file for file in csv_files if f\"{country.replace(' ', '-')}\" in file\n",
    "                ]\n",
    "            csv_mapping[country] = matching_files\n",
    "\n",
    "        # # Check the mapping\n",
    "        # for country, files in csv_mapping.items():\n",
    "        #     file_names = [os.path.basename(file) for file in files]\n",
    "        #     print(f\"  Country: {country} -> Files: {file_names}\")\n",
    "\n",
    "    return csv_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_mapping_family = get_csv_mapping(EXP_PROFILES_EXPAND_PATH, family_types_json, \"family\")\n",
    "print(\"Family CSV Mapping:\")\n",
    "display(csv_mapping_family)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_mapping_weather = get_csv_mapping(EXP_WEATHER_EXPAND_PATH, family_types_json, \"weather\")\n",
    "print(\"\\nWeather CSV Mapping\")\n",
    "display(csv_mapping_weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Energy Signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_family_and_weather_debug(family_data, weather_data):\n",
    "    if 'datetime' not in family_data.columns or 'datetime' not in weather_data.columns:\n",
    "        raise KeyError(\"Both family_data and weather_data must contain a 'datetime' column.\")\n",
    "\n",
    "    # Perform an outer merge to identify mismatches\n",
    "    master_data = pd.merge(\n",
    "        family_data,\n",
    "        weather_data,\n",
    "        on=['datetime'],\n",
    "        how='outer',\n",
    "        indicator=True  # Add a column to show the merge status\n",
    "    )\n",
    "\n",
    "    # Separate unmatched rows\n",
    "    unmatched_family = master_data[master_data['_merge'] == 'left_only']\n",
    "    unmatched_weather = master_data[master_data['_merge'] == 'right_only']\n",
    "\n",
    "    # Keep only the successfully matched rows\n",
    "    master_data = master_data[master_data['_merge'] == 'both'].drop(columns=['_merge'])\n",
    "\n",
    "    # Remove duplicate columns from the merge (_x and _y)\n",
    "    for col in master_data.columns:\n",
    "        if col.endswith('_x') and col[:-2] + '_y' in master_data.columns:\n",
    "            master_data.rename(columns={col: col[:-2]}, inplace=True)\n",
    "            master_data.drop(columns=[col[:-2] + '_y'], inplace=True)\n",
    "\n",
    "    return master_data, unmatched_family, unmatched_weather\n",
    "\n",
    "\n",
    "def combine_family_and_weather(family_csv_mapping, weather_csv_mapping, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for country, family_files in family_csv_mapping.items():\n",
    "        print(f\"\\nProcessing country: {country}\")\n",
    "        weather_file = weather_csv_mapping.get(country, [None])[0]\n",
    "        if not weather_file or not os.path.isfile(weather_file):\n",
    "            print(f\"Weather file missing for {country}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        weather_data = pd.read_csv(weather_file, parse_dates=['datetime'])\n",
    "        print(f\"Weather data loaded for {country}: {weather_file}\")\n",
    "\n",
    "        for family_type, family_file_list in family_files.items():\n",
    "            family_file = family_file_list[0]\n",
    "            if not os.path.isfile(family_file):\n",
    "                print(f\"Family file missing for {family_type} in {country}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            family_data = pd.read_csv(family_file, parse_dates=['datetime'])\n",
    "\n",
    "            if 'datetime' not in family_data.columns:\n",
    "                raise KeyError(\"The 'datetime' column is required in family_data.\")\n",
    "\n",
    "            master_data, unmatched_family, unmatched_weather = combine_family_and_weather_debug(family_data, weather_data)\n",
    "\n",
    "            formatted_country = country.replace(\" \", \"-\")\n",
    "            formatted_family_type = family_type.replace(\" \", \"-\").replace(\"'\", \"-\")\n",
    "            master_file_path = os.path.join(output_dir, f\"{formatted_country}_{formatted_family_type}_combined.csv\")\n",
    "\n",
    "            # Save combined data\n",
    "            master_data.to_csv(master_file_path, index=False)\n",
    "            print(f\"Combined data saved for {country} - {family_type}: {master_file_path}\")\n",
    "\n",
    "            # Save unmatched data only if non-empty\n",
    "            if not unmatched_family.empty:\n",
    "                unmatched_family_path = os.path.join(output_dir, f\"{formatted_country}_{formatted_family_type}_unmatched_family.csv\")\n",
    "                unmatched_family.to_csv(unmatched_family_path, index=False)\n",
    "                print(f\"Unmatched family rows saved: {unmatched_family_path}\")\n",
    "            # else:\n",
    "            #     print(f\"No unmatched family rows for {country} - {family_type}\")\n",
    "\n",
    "            if not unmatched_weather.empty:\n",
    "                unmatched_weather_path = os.path.join(output_dir, f\"{formatted_country}_{formatted_family_type}_unmatched_weather.csv\")\n",
    "                unmatched_weather.to_csv(unmatched_weather_path, index=False)\n",
    "                print(f\"Unmatched weather rows saved: {unmatched_weather_path}\")\n",
    "            # else:\n",
    "                # print(f\"No unmatched weather rows for {country} - {family_type}\")\n",
    "            # break\n",
    "        # break\n",
    "\n",
    "\n",
    "combine_family_and_weather(csv_mapping_family, csv_mapping_weather, CSV_FINAL_PROFILES_WEATHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_combined(PROJ_PATH, family_types_json):    \n",
    "    family_types = {entry[\"Country\"]: [family[\"Family Type\"] for family in entry[\"Families\"]] for entry in family_types_json}\n",
    "    \n",
    "    # Get all CSV file paths in the folder\n",
    "    csv_files = glob.glob(f\"{PROJ_PATH}/*.csv\")\n",
    "\n",
    "    # Create a dictionary to map parsed JSON to CSV files\n",
    "    csv_mapping = {}\n",
    "    for country, families in family_types.items():\n",
    "        csv_mapping[country] = {}\n",
    "        for family_type in families:\n",
    "            # Find matching CSV files for this country and family type\n",
    "            family_type_clean = family_type.replace(' ', '-').replace(\"'\", '-')\n",
    "            matching_files = [\n",
    "                # file for file in csv_files if f\"{country}_{family_type.replace(' ', '_')}\" in file\n",
    "                file for file in csv_files if f\"{country.replace(' ', '-')}_{family_type_clean}\" in file\n",
    "            ]\n",
    "            csv_mapping[country][family_type] = matching_files\n",
    "\n",
    "    return csv_mapping\n",
    "\n",
    "\n",
    "csv_combined_mapping = get_df_combined(CSV_FINAL_PROFILES_WEATHER, family_types_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(data, aggregation_level=\"daily\"):\n",
    "    \"\"\"\n",
    "    Aggregates the given data to the specified level.\n",
    "\n",
    "    Parameters:\n",
    "    - data (pd.DataFrame): The input data containing hourly information.\n",
    "    - aggregation_level (str): The level of aggregation ('daily', 'weekly', 'monthly', 'seasonal').\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: The aggregated data.\n",
    "    \"\"\"\n",
    "    # Add necessary grouping columns to the data\n",
    "    if 'year' not in data.columns:\n",
    "        data['year'] = data['datetime'].dt.year\n",
    "    if 'month' not in data.columns:\n",
    "        data['month'] = data['datetime'].dt.month\n",
    "    if 'week' not in data.columns:\n",
    "        data['week'] = data['datetime'].dt.isocalendar().week\n",
    "    if 'day' not in data.columns:\n",
    "        data['day'] = data['datetime'].dt.day\n",
    "\n",
    "    # Define grouping columns based on aggregation level\n",
    "    if aggregation_level == \"daily\":\n",
    "        group_cols = [\"year\", \"season\", \"quarter\", \"month\", \"week\", \"day\", \"day_name\"] #, \"is_weekend\", \"is_holiday\", \"pattern\"]\n",
    "    elif aggregation_level == \"weekly\":\n",
    "        group_cols = [\"year\", \"week\"]\n",
    "    elif aggregation_level == \"monthly\":\n",
    "        group_cols = [\"year\", \"month\"]\n",
    "    elif aggregation_level == \"seasonal\":\n",
    "        group_cols = [\"year\", \"season\"]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid aggregation level. Choose from 'daily', 'weekly', 'monthly', or 'seasonal'.\")\n",
    "\n",
    "    # Define aggregation functions for different columns\n",
    "    aggregation_functions = {\n",
    "        \"temperature_value\": \"mean\",\n",
    "        \"humidity_value\": \"mean\",\n",
    "        \"solrad-diffuse_value\": \"mean\",\n",
    "        \"solrad-direct_value\": \"mean\",\n",
    "        \"wind-speed_value\": \"mean\",\n",
    "        \"total_electricity_usage\": \"sum\",\n",
    "        'heating_consumption': 'sum',\n",
    "        'cooling_consumption': 'sum',\n",
    "        # # Sum consumptions for individual family members\n",
    "        **{col: 'sum' for col in data.columns if 'consumption' in col and col not in ['heating_consumption', 'cooling_consumption']},\n",
    "        \"is_weekend\": \"sum\",\n",
    "        \"is_holiday\": \"sum\",\n",
    "        # \"pattern\": \"first\" if aggregation_level == \"daily\" else None,\n",
    "    }\n",
    "\n",
    "    # Drop `None` aggregation functions\n",
    "    aggregation_functions = {k: v for k, v in aggregation_functions.items() if v is not None}\n",
    "\n",
    "    # Group and aggregate the data\n",
    "    aggregated_data = data.groupby(group_cols).agg(aggregation_functions).reset_index()\n",
    "\n",
    "    # Identify numeric columns (excluding grouping columns)\n",
    "    numeric_columns = aggregated_data.select_dtypes(include=['float64', 'int64']).columns\n",
    "    holiday_columns = ['is_weekend', 'is_holiday']\n",
    "\n",
    "    # Divide numeric columns by 24\n",
    "    aggregated_data[holiday_columns] = aggregated_data[holiday_columns] / 24\n",
    "\n",
    "    # Round numeric values to the specified number of decimals\n",
    "    aggregated_data[numeric_columns] = aggregated_data[numeric_columns].round(2)\n",
    "\n",
    "    # Handle specific columns for weekend/holiday aggregation\n",
    "    if aggregation_level != \"daily\":\n",
    "        aggregated_data.rename(columns={\"is_weekend\": \"total_weekend_days\", \"is_holiday\": \"total_holiday_days\"}, inplace=True)\n",
    "\n",
    "    # Drop `pattern` column for non-daily aggregations\n",
    "    if aggregation_level != \"daily\" and \"pattern\" in aggregated_data.columns:\n",
    "        aggregated_data.drop(columns=[\"pattern\"], inplace=True)\n",
    "\n",
    "    return aggregated_data\n",
    "\n",
    "\n",
    "def plot_energy_signatures_sorted(data, x_col, y_col, family_member_counts, country, ax_list, season_colors=None):\n",
    "    \"\"\"\n",
    "    Plots energy signatures for a specific country with subplots for each family type.\n",
    "    \"\"\"\n",
    "\n",
    "    # Sort family types by number of members\n",
    "    sorted_families = sorted(\n",
    "        data['family_type'].unique(),\n",
    "        key=lambda ft: family_member_counts[country].get(ft, 0)  # Default to 0 if family type not in the mapping\n",
    "    )\n",
    "\n",
    "    # Determine consistent y-limits for the country\n",
    "    y_min = data[y_col].min() - 0.05 * data[y_col].max()\n",
    "    y_max = data[y_col].max() + 0.05 * data[y_col].max()\n",
    "\n",
    "    # Iterate over family types and plot on the corresponding subplot\n",
    "    for ax, family in zip(ax_list, sorted_families[:NUMBER_FAMILIES_PER_COUNTRY]):\n",
    "        family_data = data[data['family_type'] == family]\n",
    "        \n",
    "        if season_colors != None:\n",
    "            # Plot data for each season\n",
    "            for season, color in season_colors.items():\n",
    "                season_data = family_data[family_data['season'] == season]\n",
    "                ax.scatter(\n",
    "                    season_data[x_col],\n",
    "                    season_data[y_col],\n",
    "                    label=season,\n",
    "                    color=color,\n",
    "                    alpha=0.7\n",
    "                )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                family_data[x_col],\n",
    "                family_data[y_col],\n",
    "                # color='orange',\n",
    "                # alpha=0.7\n",
    "            )\n",
    "\n",
    "        # Set subplot title and labels\n",
    "        ax.set_title(f\"{family} ({family_member_counts[country].get(family, 0)} members)\", fontsize=10)\n",
    "        ax.set_xlabel(\"Outside Temperature (°C)\")\n",
    "        ax.set_ylabel(\"Total Consumption (kWh)\" if ax == ax_list[0] else \"\")  # Only add ylabel to the first subplot\n",
    "        ax.set_ylim(y_min, y_max)\n",
    "        ax.grid(True)\n",
    "    \n",
    "    # Add legend to the first subplot only\n",
    "    handles, labels = ax_list[0].get_legend_handles_labels()\n",
    "    # ax_list[0].legend(handles, labels, title=\"Season\", loc=\"upper left\")\n",
    "    if season_colors != None:\n",
    "        LEGEND_LOC = NUMBER_FAMILIES_PER_COUNTRY // 2\n",
    "        ax_list[LEGEND_LOC].legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=len(season_colors), fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for country, family_files in csv_combined_mapping.items():\n",
    "    print(f\"\\nProcessing Country: {country}\")\n",
    "    \n",
    "    # Create a new figure for each country\n",
    "    FIG, AXES = plt.subplots(1, NUMBER_FAMILIES_PER_COUNTRY, figsize=(25, 5), sharey=False)  # 5 subplots per country\n",
    "    # FIG.suptitle(f\"Energy Signature for {country}\", fontsize=16)\n",
    "    \n",
    "    country_data = []\n",
    "    \n",
    "    for family_type, family_file_list in family_files.items():\n",
    "        if len(family_file_list) > 0:\n",
    "            family_file = family_file_list[0]\n",
    "            if not os.path.isfile(family_file):\n",
    "                print(f\"\\t[MISSING-L2] Family file missing for {family_type} in {country}.\")\n",
    "            else:\n",
    "                # print(f\"\\tFamily Type: {family_type}\")\n",
    "                master_family_data = pd.read_csv(family_file, parse_dates=['datetime'])\n",
    "    \n",
    "                # Aggregating to different levels\n",
    "                if AGGREGATE_BY not in ['daily', 'seasonal', 'weekly', 'monthly']:\n",
    "                    data_aggregated = master_family_data\n",
    "                else:\n",
    "                    data_aggregated = aggregate_data(master_family_data, aggregation_level=AGGREGATE_BY)\n",
    "\n",
    "                data_aggregated['family_type'] = family_type  # Add family type to the aggregated data\n",
    "\n",
    "                # Identify columns for family members and HVAC consumption\n",
    "                hvac_columns = ['heating_consumption', 'cooling_consumption']\n",
    "\n",
    "                family_consumption_columns = [col for col in data_aggregated.columns if 'consumption' in col and col not in ['heating_consumption', 'cooling_consumption']]\n",
    "                data_aggregated['total_family_consumption'] = data_aggregated[family_consumption_columns].sum(axis=1)\n",
    "                data_aggregated['total_hvac_consumption'] = data_aggregated[hvac_columns].sum(axis=1)\n",
    "                data_aggregated.drop(columns=family_consumption_columns, inplace=True)\n",
    "\n",
    "                country_data.append(data_aggregated)\n",
    "        # break\n",
    "\n",
    "    if country_data:\n",
    "        country_data = pd.concat(country_data)  # Combine all family data for the country\n",
    "        # display(country_data)\n",
    "        x_col = \"temperature_value\"\n",
    "        y_col = \"total_electricity_usage\"\n",
    "        # y_col = \"total_family_consumption\"\n",
    "        # y_col = \"total_hvac_consumption\"\n",
    "        plot_energy_signatures_sorted(country_data, x_col, y_col, family_member_counts, country=country, ax_list=AXES, season_colors=SEASON_COLORS)\n",
    "\n",
    "    # Adjust layout and show the figure\n",
    "    plt.tight_layout()\n",
    "\n",
    "    PLOT_FOLDER = f\"{CSV_FINAL_PROFILES_WEATHER}/plots\"\n",
    "    if not os.path.exists(PLOT_FOLDER):\n",
    "        os.makedirs(PLOT_FOLDER)\n",
    "\n",
    "    if SAVE_PLOTS:\n",
    "        # Save as PNG with high resolution\n",
    "        plt.savefig(os.path.join(PLOT_FOLDER, f\"{country}.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "        # Save as PDF\n",
    "        plt.savefig(os.path.join(PLOT_FOLDER, f\"{country}.pdf\"), bbox_inches=\"tight\")\n",
    "    plt.show()\n",
    "\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
